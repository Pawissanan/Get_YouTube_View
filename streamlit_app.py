import streamlit as st
import pandas as pd
import re
from datetime import datetime
import googleapiclient.discovery as youtube

def fetch_youtube_data(api_key, channel_id, start_month_year, end_month_year):
    try:
        youtube_api = youtube.build('youtube', 'v3', developerKey=api_key)

        start_month = int(start_month_year[:2])
        start_year = int(start_month_year[2:])
        end_month = int(end_month_year[:2])
        end_year = int(end_month_year[2:])

        uploads_playlist_response = youtube_api.channels().list(
            part='contentDetails,snippet', id=channel_id).execute()

        if 'items' not in uploads_playlist_response or len(uploads_playlist_response['items']) == 0:
            st.warning(f"No items found for channel ID: {channel_id}")
            return None

        uploads_playlist_id = uploads_playlist_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        channel_name = uploads_playlist_response['items'][0]['snippet']['title']

        video_data = {
            'Channel Name': [],
            'Video Title': [],
            'View Count': [],
            'Published Date': [],
            'Description': []  # Only hashtags
        }

        next_page_token = ''
        while next_page_token is not None:
            playlist_items_response = youtube_api.playlistItems().list(
                part='contentDetails', playlistId=uploads_playlist_id,
                maxResults=50, pageToken=next_page_token).execute()
            video_ids = [item['contentDetails']['videoId'] for item in playlist_items_response['items']]

            for video_id in video_ids:
                video_response = youtube_api.videos().list(part='statistics,snippet', id=video_id).execute()
                snippet = video_response['items'][0]['snippet']
                statistics = video_response['items'][0]['statistics']

                video_title = snippet.get('title', '')
                view_count = int(statistics.get('viewCount', 0))
                published_date_str = snippet.get('publishedAt', '')
                published_date = datetime.fromisoformat(published_date_str[:-1])
                description = snippet.get('description', '')

                if start_year <= published_date.year <= end_year and start_month <= published_date.month <= end_month:
                    if keyword and keyword not in video_title.lower() and keyword not in description.lower():
                        continue # Skip videos that don't match keyword
                    hashtags = re.findall(r'#\S+', description)

                    video_data['Channel Name'].append(channel_name)
                    video_data['Video Title'].append(video_title)
                    video_data['Description'].append(', '.join(hashtags))
                    video_data['Published Date'].append(published_date.date())
                    video_data['View Count'].append(view_count)

            next_page_token = playlist_items_response.get('nextPageToken')

        return pd.DataFrame(video_data)

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        return None

# Streamlit UI
st.title("ðŸ“Š YouTube Channel View Extractor")

api_key = st.text_input("ðŸ”‘ Enter your YouTube API Key:", type="password")

channel_ids_input = st.text_area("ðŸ“º Enter YouTube Channel IDs (one per line):")
channel_ids = [c.strip() for c in channel_ids_input.splitlines() if c.strip()]

col1, col2 = st.columns(2)
with col1:
    start_month_year = st.text_input("Start Month & Year (MMYYYY)", value="")
with col2:
    end_month_year = st.text_input("End Month & Year (MMYYYY)", value="")

keyword = st.text_input("ðŸ” Filter by keyword in title or description (optional):").lower()

if st.button("Run Analysis"):
    if not api_key or not channel_ids:
        st.warning("Please enter both API key and at least one channel ID.")
    else:
        df_list = []
        with st.spinner("Fetching data from YouTube..."):
            for cid in channel_ids:
                df = fetch_youtube_data(api_key, cid, start_month_year, end_month_year)
                if df is not None and not df.empty:
                    df_list.append(df)

        if df_list:
            result_df = pd.concat(df_list, ignore_index=True)
            st.success("âœ… Data fetched successfully!")
            st.dataframe(result_df)

            # Excel download
            file_name = f"youtube_data_{start_month_year}_{end_month_year}.xlsx"
            result_df.to_excel(file_name, index=False)

            with open(file_name, "rb") as f:
                st.download_button(
                    label="ðŸ“¥ Download Excel File",
                    data=f,
                    file_name=file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.warning("No data found for the selected period.")
